{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras import optimizers, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../titanic/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  male  Q  S\n",
       "0         0       3  22.0      1      0   7.2500     1  0  1\n",
       "1         1       1  38.0      1      0  71.2833     0  0  0\n",
       "2         1       3  26.0      0      0   7.9250     0  0  1\n",
       "3         1       1  35.0      1      0  53.1000     0  0  1\n",
       "4         0       3  35.0      0      0   8.0500     1  0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train.to_numpy()\n",
    "X = data[:,1:]\n",
    "y = data[:,0]\n",
    "# y = to_categorical(y,num_classes=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.6427 - accuracy: 0.6162 - val_loss: 0.6310 - val_accuracy: 0.6292\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6321 - accuracy: 0.6162 - val_loss: 0.6217 - val_accuracy: 0.6292\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6268 - accuracy: 0.6263 - val_loss: 0.6146 - val_accuracy: 0.6742\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6228 - accuracy: 0.6637 - val_loss: 0.6091 - val_accuracy: 0.6742\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6197 - accuracy: 0.6837 - val_loss: 0.6045 - val_accuracy: 0.7079\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6174 - accuracy: 0.6787 - val_loss: 0.6015 - val_accuracy: 0.6742\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6157 - accuracy: 0.6787 - val_loss: 0.5994 - val_accuracy: 0.6629\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6146 - accuracy: 0.6787 - val_loss: 0.5966 - val_accuracy: 0.6629\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6131 - accuracy: 0.6775 - val_loss: 0.5942 - val_accuracy: 0.6629\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6122 - accuracy: 0.6775 - val_loss: 0.5921 - val_accuracy: 0.6742\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6110 - accuracy: 0.6762 - val_loss: 0.5896 - val_accuracy: 0.6854\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6101 - accuracy: 0.6787 - val_loss: 0.5876 - val_accuracy: 0.6854\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6091 - accuracy: 0.6762 - val_loss: 0.5860 - val_accuracy: 0.6854\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6086 - accuracy: 0.6812 - val_loss: 0.5848 - val_accuracy: 0.6854\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.6080 - accuracy: 0.6812 - val_loss: 0.5833 - val_accuracy: 0.6742\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6075 - accuracy: 0.6800 - val_loss: 0.5820 - val_accuracy: 0.6742\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6068 - accuracy: 0.6825 - val_loss: 0.5809 - val_accuracy: 0.6742\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6066 - accuracy: 0.6812 - val_loss: 0.5796 - val_accuracy: 0.6742\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6059 - accuracy: 0.6850 - val_loss: 0.5786 - val_accuracy: 0.6742\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6055 - accuracy: 0.6837 - val_loss: 0.5771 - val_accuracy: 0.6854\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6049 - accuracy: 0.6862 - val_loss: 0.5767 - val_accuracy: 0.6854\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6047 - accuracy: 0.6862 - val_loss: 0.5760 - val_accuracy: 0.6742\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6045 - accuracy: 0.6862 - val_loss: 0.5750 - val_accuracy: 0.6742\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6040 - accuracy: 0.6875 - val_loss: 0.5744 - val_accuracy: 0.6854\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6040 - accuracy: 0.6875 - val_loss: 0.5741 - val_accuracy: 0.6742\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6035 - accuracy: 0.6862 - val_loss: 0.5740 - val_accuracy: 0.6742\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6032 - accuracy: 0.6888 - val_loss: 0.5731 - val_accuracy: 0.6742\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.6030 - accuracy: 0.6875 - val_loss: 0.5725 - val_accuracy: 0.6742\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6028 - accuracy: 0.6900 - val_loss: 0.5721 - val_accuracy: 0.6854\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6026 - accuracy: 0.6888 - val_loss: 0.5716 - val_accuracy: 0.6854\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6022 - accuracy: 0.6913 - val_loss: 0.5711 - val_accuracy: 0.6742\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6019 - accuracy: 0.6913 - val_loss: 0.5705 - val_accuracy: 0.6742\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6017 - accuracy: 0.6913 - val_loss: 0.5705 - val_accuracy: 0.6742\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6017 - accuracy: 0.6888 - val_loss: 0.5701 - val_accuracy: 0.6742\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6015 - accuracy: 0.6913 - val_loss: 0.5695 - val_accuracy: 0.6742\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6016 - accuracy: 0.6900 - val_loss: 0.5692 - val_accuracy: 0.6742\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 98us/step - loss: 0.6008 - accuracy: 0.6913 - val_loss: 0.5688 - val_accuracy: 0.6742\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6007 - accuracy: 0.6925 - val_loss: 0.5680 - val_accuracy: 0.6742\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6008 - accuracy: 0.6913 - val_loss: 0.5685 - val_accuracy: 0.6742\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6004 - accuracy: 0.6925 - val_loss: 0.5684 - val_accuracy: 0.6629\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6002 - accuracy: 0.6925 - val_loss: 0.5679 - val_accuracy: 0.6629\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.5998 - accuracy: 0.6925 - val_loss: 0.5674 - val_accuracy: 0.6629\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.5995 - accuracy: 0.6925 - val_loss: 0.5668 - val_accuracy: 0.6742\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5996 - accuracy: 0.6925 - val_loss: 0.5664 - val_accuracy: 0.6742\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.5994 - accuracy: 0.6925 - val_loss: 0.5660 - val_accuracy: 0.6629\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.5992 - accuracy: 0.6925 - val_loss: 0.5659 - val_accuracy: 0.6629\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.5991 - accuracy: 0.6913 - val_loss: 0.5655 - val_accuracy: 0.6629\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.5989 - accuracy: 0.6925 - val_loss: 0.5653 - val_accuracy: 0.6629\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.5986 - accuracy: 0.6900 - val_loss: 0.5648 - val_accuracy: 0.6742\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.5985 - accuracy: 0.6925 - val_loss: 0.5645 - val_accuracy: 0.6742\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(Dense(1,input_dim=8,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 257us/step - loss: 2.2920 - accuracy: 0.5188 - val_loss: 0.9292 - val_accuracy: 0.6292\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.1431 - accuracy: 0.6500 - val_loss: 1.7775 - val_accuracy: 0.6292\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 67us/step - loss: 1.6083 - accuracy: 0.5713 - val_loss: 1.4711 - val_accuracy: 0.6404\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 51us/step - loss: 1.2598 - accuracy: 0.6162 - val_loss: 1.1745 - val_accuracy: 0.6404\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 1.2584 - accuracy: 0.6338 - val_loss: 1.6772 - val_accuracy: 0.3596\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 1.3615 - accuracy: 0.5925 - val_loss: 0.9979 - val_accuracy: 0.6517\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 1.0903 - accuracy: 0.6350 - val_loss: 0.7244 - val_accuracy: 0.6404\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.0548 - accuracy: 0.6288 - val_loss: 1.7192 - val_accuracy: 0.3596\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.4143 - accuracy: 0.5700 - val_loss: 1.2647 - val_accuracy: 0.6180\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.0549 - accuracy: 0.6250 - val_loss: 0.8513 - val_accuracy: 0.6854\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 1.3251 - accuracy: 0.6350 - val_loss: 0.6677 - val_accuracy: 0.6854\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.1025 - accuracy: 0.6400 - val_loss: 2.4086 - val_accuracy: 0.6292\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.9325 - accuracy: 0.5650 - val_loss: 0.8854 - val_accuracy: 0.6629\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 38us/step - loss: 1.1813 - accuracy: 0.6125 - val_loss: 0.6766 - val_accuracy: 0.6854\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.1373 - accuracy: 0.6062 - val_loss: 0.9971 - val_accuracy: 0.5843\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 1.0759 - accuracy: 0.6275 - val_loss: 1.0438 - val_accuracy: 0.6404\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.9241 - accuracy: 0.6400 - val_loss: 0.7139 - val_accuracy: 0.6854\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.9623 - accuracy: 0.6350 - val_loss: 0.6957 - val_accuracy: 0.7191\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 1.1090 - accuracy: 0.6175 - val_loss: 0.9510 - val_accuracy: 0.7191\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 111us/step - loss: 0.9937 - accuracy: 0.6612 - val_loss: 0.8971 - val_accuracy: 0.6292\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 1.2869 - accuracy: 0.6275 - val_loss: 0.6072 - val_accuracy: 0.6966\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.9498 - accuracy: 0.6275 - val_loss: 0.5981 - val_accuracy: 0.7079\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.1250 - accuracy: 0.6425 - val_loss: 1.0320 - val_accuracy: 0.6404\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 50us/step - loss: 1.3186 - accuracy: 0.6175 - val_loss: 1.9664 - val_accuracy: 0.6292\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 35us/step - loss: 1.3700 - accuracy: 0.6375 - val_loss: 1.2103 - val_accuracy: 0.4607\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.1539 - accuracy: 0.5863 - val_loss: 0.7343 - val_accuracy: 0.7079\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 1.1526 - accuracy: 0.6162 - val_loss: 1.1291 - val_accuracy: 0.6292\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 1.0998 - accuracy: 0.6325 - val_loss: 1.0807 - val_accuracy: 0.5618\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 1.0279 - accuracy: 0.6488 - val_loss: 2.0937 - val_accuracy: 0.3596\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.2269 - accuracy: 0.6263 - val_loss: 1.5274 - val_accuracy: 0.6292\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 34us/step - loss: 1.1161 - accuracy: 0.6488 - val_loss: 0.9336 - val_accuracy: 0.6292\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.1180 - accuracy: 0.6263 - val_loss: 1.8935 - val_accuracy: 0.3596\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.1604 - accuracy: 0.6300 - val_loss: 1.6211 - val_accuracy: 0.3708\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 1.1900 - accuracy: 0.6025 - val_loss: 2.5253 - val_accuracy: 0.6292\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.2572 - accuracy: 0.6450 - val_loss: 1.1939 - val_accuracy: 0.6067\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 1.0642 - accuracy: 0.6550 - val_loss: 1.0603 - val_accuracy: 0.5393\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.6099 - accuracy: 0.5475 - val_loss: 0.8816 - val_accuracy: 0.6292\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.2269 - accuracy: 0.5838 - val_loss: 1.9624 - val_accuracy: 0.6292\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 1.2685 - accuracy: 0.6575 - val_loss: 0.9676 - val_accuracy: 0.6404\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.1063 - accuracy: 0.6325 - val_loss: 0.6664 - val_accuracy: 0.7303\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 1.0417 - accuracy: 0.6538 - val_loss: 2.3014 - val_accuracy: 0.4157\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.3207 - accuracy: 0.6488 - val_loss: 1.0550 - val_accuracy: 0.6292\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 1.1620 - accuracy: 0.6175 - val_loss: 1.0170 - val_accuracy: 0.4944\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.2455 - accuracy: 0.5900 - val_loss: 1.0655 - val_accuracy: 0.6404\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 1.0076 - accuracy: 0.6450 - val_loss: 1.0755 - val_accuracy: 0.6404\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.8963 - accuracy: 0.6650 - val_loss: 0.6737 - val_accuracy: 0.6742\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 1.4842 - accuracy: 0.5987 - val_loss: 0.7043 - val_accuracy: 0.7191\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.9537 - accuracy: 0.6275 - val_loss: 0.8381 - val_accuracy: 0.6742\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.0710 - accuracy: 0.6662 - val_loss: 0.5879 - val_accuracy: 0.7191\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.0724 - accuracy: 0.6300 - val_loss: 1.9487 - val_accuracy: 0.6292\n"
     ]
    }
   ],
   "source": [
    "history2 = new_model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(32,input_dim=8,activation='sigmoid'))\n",
    "model_2.add(Dense(32,activation='sigmoid'))\n",
    "model_2.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/30\n",
      "800/800 [==============================] - 0s 413us/step - loss: 0.8965 - accuracy: 0.3837 - val_loss: 0.8607 - val_accuracy: 0.3708\n",
      "Epoch 2/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.8235 - accuracy: 0.3837 - val_loss: 0.7970 - val_accuracy: 0.3708\n",
      "Epoch 3/30\n",
      "800/800 [==============================] - 0s 420us/step - loss: 0.7706 - accuracy: 0.3837 - val_loss: 0.7540 - val_accuracy: 0.3708\n",
      "Epoch 4/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.7354 - accuracy: 0.3837 - val_loss: 0.7255 - val_accuracy: 0.3708\n",
      "Epoch 5/30\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.7124 - accuracy: 0.3837 - val_loss: 0.7060 - val_accuracy: 0.3708\n",
      "Epoch 6/30\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6968 - accuracy: 0.4300 - val_loss: 0.6923 - val_accuracy: 0.5730\n",
      "Epoch 7/30\n",
      "800/800 [==============================] - 0s 142us/step - loss: 0.6862 - accuracy: 0.6150 - val_loss: 0.6840 - val_accuracy: 0.6517\n",
      "Epoch 8/30\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6796 - accuracy: 0.6175 - val_loss: 0.6770 - val_accuracy: 0.6292\n",
      "Epoch 9/30\n",
      "800/800 [==============================] - 0s 101us/step - loss: 0.6744 - accuracy: 0.6162 - val_loss: 0.6719 - val_accuracy: 0.6292\n",
      "Epoch 10/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6705 - accuracy: 0.6162 - val_loss: 0.6686 - val_accuracy: 0.6292\n",
      "Epoch 11/30\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6679 - accuracy: 0.6162 - val_loss: 0.6650 - val_accuracy: 0.6292\n",
      "Epoch 12/30\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.6654 - accuracy: 0.6162 - val_loss: 0.6632 - val_accuracy: 0.6292\n",
      "Epoch 13/30\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6641 - accuracy: 0.6162 - val_loss: 0.6611 - val_accuracy: 0.6292\n",
      "Epoch 14/30\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6626 - accuracy: 0.6162 - val_loss: 0.6600 - val_accuracy: 0.6292\n",
      "Epoch 15/30\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6619 - accuracy: 0.6162 - val_loss: 0.6589 - val_accuracy: 0.6292\n",
      "Epoch 16/30\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6610 - accuracy: 0.6162 - val_loss: 0.6583 - val_accuracy: 0.6292\n",
      "Epoch 17/30\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6605 - accuracy: 0.6162 - val_loss: 0.6573 - val_accuracy: 0.6292\n",
      "Epoch 18/30\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6599 - accuracy: 0.6162 - val_loss: 0.6565 - val_accuracy: 0.6292\n",
      "Epoch 19/30\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6593 - accuracy: 0.6162 - val_loss: 0.6557 - val_accuracy: 0.6292\n",
      "Epoch 20/30\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6588 - accuracy: 0.6162 - val_loss: 0.6550 - val_accuracy: 0.6292\n",
      "Epoch 21/30\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6581 - accuracy: 0.6162 - val_loss: 0.6545 - val_accuracy: 0.6292\n",
      "Epoch 22/30\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6578 - accuracy: 0.6162 - val_loss: 0.6535 - val_accuracy: 0.6292\n",
      "Epoch 23/30\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.6654 - accuracy: 0.59 - 0s 35us/step - loss: 0.6571 - accuracy: 0.6162 - val_loss: 0.6530 - val_accuracy: 0.6292\n",
      "Epoch 24/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6566 - accuracy: 0.6162 - val_loss: 0.6524 - val_accuracy: 0.6292\n",
      "Epoch 25/30\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6562 - accuracy: 0.6162 - val_loss: 0.6518 - val_accuracy: 0.6292\n",
      "Epoch 26/30\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6558 - accuracy: 0.6162 - val_loss: 0.6515 - val_accuracy: 0.6292\n",
      "Epoch 27/30\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6553 - accuracy: 0.6162 - val_loss: 0.6509 - val_accuracy: 0.6292\n",
      "Epoch 28/30\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6550 - accuracy: 0.6162 - val_loss: 0.6506 - val_accuracy: 0.6292\n",
      "Epoch 29/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6546 - accuracy: 0.6162 - val_loss: 0.6497 - val_accuracy: 0.6292\n",
      "Epoch 30/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6541 - accuracy: 0.6162 - val_loss: 0.6492 - val_accuracy: 0.6292\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_2.fit(X, y, epochs=30, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Nodes to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_256 = Sequential()\n",
    "model_256.add(Dense(256,input_dim=8,activation='sigmoid'))\n",
    "model_256.add(Dropout(0.2))\n",
    "model_256.add(Dense(256,activation='sigmoid'))\n",
    "model_256.add(Dropout(0.2))\n",
    "model_256.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_256.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/60\n",
      "800/800 [==============================] - 0s 496us/step - loss: 0.7093 - accuracy: 0.5038 - val_loss: 0.6576 - val_accuracy: 0.6292\n",
      "Epoch 2/60\n",
      "800/800 [==============================] - 0s 354us/step - loss: 0.6789 - accuracy: 0.5925 - val_loss: 0.6534 - val_accuracy: 0.6292\n",
      "Epoch 3/60\n",
      "800/800 [==============================] - 0s 100us/step - loss: 0.6766 - accuracy: 0.5962 - val_loss: 0.6495 - val_accuracy: 0.6292\n",
      "Epoch 4/60\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6831 - accuracy: 0.5875 - val_loss: 0.6465 - val_accuracy: 0.6292\n",
      "Epoch 5/60\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6689 - accuracy: 0.6025 - val_loss: 0.6430 - val_accuracy: 0.6292\n",
      "Epoch 6/60\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6673 - accuracy: 0.6225 - val_loss: 0.6397 - val_accuracy: 0.6292\n",
      "Epoch 7/60\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6781 - accuracy: 0.5900 - val_loss: 0.6372 - val_accuracy: 0.6292\n",
      "Epoch 8/60\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6659 - accuracy: 0.6150 - val_loss: 0.6348 - val_accuracy: 0.6292\n",
      "Epoch 9/60\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6680 - accuracy: 0.6125 - val_loss: 0.6339 - val_accuracy: 0.6292\n",
      "Epoch 10/60\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6606 - accuracy: 0.6250 - val_loss: 0.6307 - val_accuracy: 0.6292\n",
      "Epoch 11/60\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6607 - accuracy: 0.6025 - val_loss: 0.6271 - val_accuracy: 0.6292\n",
      "Epoch 12/60\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6590 - accuracy: 0.6075 - val_loss: 0.6258 - val_accuracy: 0.6292\n",
      "Epoch 13/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6590 - accuracy: 0.6137 - val_loss: 0.6234 - val_accuracy: 0.6292\n",
      "Epoch 14/60\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.6590 - accuracy: 0.6162 - val_loss: 0.6238 - val_accuracy: 0.6742\n",
      "Epoch 15/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6549 - accuracy: 0.6338 - val_loss: 0.6224 - val_accuracy: 0.6629\n",
      "Epoch 16/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6509 - accuracy: 0.6275 - val_loss: 0.6177 - val_accuracy: 0.6404\n",
      "Epoch 17/60\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6541 - accuracy: 0.6250 - val_loss: 0.6162 - val_accuracy: 0.6404\n",
      "Epoch 18/60\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.6581 - accuracy: 0.6263 - val_loss: 0.6181 - val_accuracy: 0.6742\n",
      "Epoch 19/60\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6498 - accuracy: 0.6313 - val_loss: 0.6153 - val_accuracy: 0.6292\n",
      "Epoch 20/60\n",
      "800/800 [==============================] - 0s 95us/step - loss: 0.6567 - accuracy: 0.6313 - val_loss: 0.6125 - val_accuracy: 0.6404\n",
      "Epoch 21/60\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6409 - accuracy: 0.6375 - val_loss: 0.6132 - val_accuracy: 0.6742\n",
      "Epoch 22/60\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6475 - accuracy: 0.6388 - val_loss: 0.6093 - val_accuracy: 0.6629\n",
      "Epoch 23/60\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6489 - accuracy: 0.6263 - val_loss: 0.6082 - val_accuracy: 0.6629\n",
      "Epoch 24/60\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6331 - accuracy: 0.6575 - val_loss: 0.6087 - val_accuracy: 0.6854\n",
      "Epoch 25/60\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6433 - accuracy: 0.6425 - val_loss: 0.6061 - val_accuracy: 0.6629\n",
      "Epoch 26/60\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6374 - accuracy: 0.6575 - val_loss: 0.6055 - val_accuracy: 0.6629\n",
      "Epoch 27/60\n",
      "800/800 [==============================] - 0s 77us/step - loss: 0.6375 - accuracy: 0.6413 - val_loss: 0.6044 - val_accuracy: 0.6854\n",
      "Epoch 28/60\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6328 - accuracy: 0.6538 - val_loss: 0.6034 - val_accuracy: 0.6854\n",
      "Epoch 29/60\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6481 - accuracy: 0.6425 - val_loss: 0.6022 - val_accuracy: 0.6742\n",
      "Epoch 30/60\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6422 - accuracy: 0.6562 - val_loss: 0.6013 - val_accuracy: 0.6742\n",
      "Epoch 31/60\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6415 - accuracy: 0.6263 - val_loss: 0.6004 - val_accuracy: 0.6854\n",
      "Epoch 32/60\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6342 - accuracy: 0.6700 - val_loss: 0.6027 - val_accuracy: 0.6742\n",
      "Epoch 33/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6308 - accuracy: 0.6600 - val_loss: 0.5985 - val_accuracy: 0.6742\n",
      "Epoch 34/60\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6393 - accuracy: 0.6525 - val_loss: 0.5978 - val_accuracy: 0.6629\n",
      "Epoch 35/60\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6300 - accuracy: 0.6587 - val_loss: 0.5971 - val_accuracy: 0.6629\n",
      "Epoch 36/60\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6321 - accuracy: 0.6538 - val_loss: 0.5966 - val_accuracy: 0.6966\n",
      "Epoch 37/60\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.6391 - accuracy: 0.6488 - val_loss: 0.5958 - val_accuracy: 0.6517\n",
      "Epoch 38/60\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6369 - accuracy: 0.6438 - val_loss: 0.5954 - val_accuracy: 0.6854\n",
      "Epoch 39/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6379 - accuracy: 0.6513 - val_loss: 0.5947 - val_accuracy: 0.6517\n",
      "Epoch 40/60\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6348 - accuracy: 0.6625 - val_loss: 0.5939 - val_accuracy: 0.6629\n",
      "Epoch 41/60\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6223 - accuracy: 0.6600 - val_loss: 0.5940 - val_accuracy: 0.6629\n",
      "Epoch 42/60\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6309 - accuracy: 0.6600 - val_loss: 0.5943 - val_accuracy: 0.6742\n",
      "Epoch 43/60\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6233 - accuracy: 0.6475 - val_loss: 0.5922 - val_accuracy: 0.6517\n",
      "Epoch 44/60\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6319 - accuracy: 0.6562 - val_loss: 0.5922 - val_accuracy: 0.6629\n",
      "Epoch 45/60\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6235 - accuracy: 0.6737 - val_loss: 0.5920 - val_accuracy: 0.6742\n",
      "Epoch 46/60\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6264 - accuracy: 0.6612 - val_loss: 0.5912 - val_accuracy: 0.6629\n",
      "Epoch 47/60\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6240 - accuracy: 0.6600 - val_loss: 0.5909 - val_accuracy: 0.6742\n",
      "Epoch 48/60\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6305 - accuracy: 0.6687 - val_loss: 0.5906 - val_accuracy: 0.6742\n",
      "Epoch 49/60\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6281 - accuracy: 0.6612 - val_loss: 0.5900 - val_accuracy: 0.6629\n",
      "Epoch 50/60\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6361 - accuracy: 0.6400 - val_loss: 0.5901 - val_accuracy: 0.6742\n",
      "Epoch 51/60\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6282 - accuracy: 0.6687 - val_loss: 0.5890 - val_accuracy: 0.6629\n",
      "Epoch 52/60\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6284 - accuracy: 0.6650 - val_loss: 0.5885 - val_accuracy: 0.6629\n",
      "Epoch 53/60\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6193 - accuracy: 0.6825 - val_loss: 0.5882 - val_accuracy: 0.6629\n",
      "Epoch 54/60\n",
      "800/800 [==============================] - 0s 121us/step - loss: 0.6195 - accuracy: 0.6650 - val_loss: 0.5894 - val_accuracy: 0.6742\n",
      "Epoch 55/60\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6278 - accuracy: 0.6525 - val_loss: 0.5876 - val_accuracy: 0.6629\n",
      "Epoch 56/60\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.6186 - accuracy: 0.6837 - val_loss: 0.5877 - val_accuracy: 0.6517\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 77us/step - loss: 0.6352 - accuracy: 0.6463 - val_loss: 0.5869 - val_accuracy: 0.6629\n",
      "Epoch 58/60\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.6309 - accuracy: 0.6625 - val_loss: 0.5867 - val_accuracy: 0.6742\n",
      "Epoch 59/60\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6251 - accuracy: 0.6687 - val_loss: 0.5864 - val_accuracy: 0.6742\n",
      "Epoch 60/60\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6294 - accuracy: 0.6625 - val_loss: 0.5872 - val_accuracy: 0.6742\n"
     ]
    }
   ],
   "source": [
    "model_256_history = model_256.fit(X, y, epochs=60, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model = Sequential()\n",
    "relu_model.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_model.add(Dropout(0.2))\n",
    "relu_model.add(Dense(256,activation='relu'))\n",
    "relu_model.add(Dropout(0.2))\n",
    "relu_model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 429us/step - loss: 1.4689 - accuracy: 0.5850 - val_loss: 0.6063 - val_accuracy: 0.7079\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.9568 - accuracy: 0.6300 - val_loss: 0.5830 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.9225 - accuracy: 0.6175 - val_loss: 0.6098 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.7493 - accuracy: 0.6550 - val_loss: 0.8203 - val_accuracy: 0.6292\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.9034 - accuracy: 0.6200 - val_loss: 0.6109 - val_accuracy: 0.6629\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.8086 - accuracy: 0.6200 - val_loss: 0.5742 - val_accuracy: 0.6966\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.7530 - accuracy: 0.6750 - val_loss: 0.5789 - val_accuracy: 0.7303\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.7313 - accuracy: 0.6125 - val_loss: 1.0132 - val_accuracy: 0.6292\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 132us/step - loss: 0.8058 - accuracy: 0.6338 - val_loss: 0.6583 - val_accuracy: 0.7191\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.6871 - accuracy: 0.6637 - val_loss: 0.5995 - val_accuracy: 0.7079\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.7313 - accuracy: 0.6438 - val_loss: 0.5520 - val_accuracy: 0.7191\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6970 - accuracy: 0.6675 - val_loss: 0.5561 - val_accuracy: 0.7303\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6812 - accuracy: 0.6675 - val_loss: 0.5433 - val_accuracy: 0.6966\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6184 - accuracy: 0.6913 - val_loss: 0.5758 - val_accuracy: 0.6292\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6548 - accuracy: 0.6550 - val_loss: 0.5705 - val_accuracy: 0.6404\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 115us/step - loss: 0.6720 - accuracy: 0.6650 - val_loss: 0.5492 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 156us/step - loss: 0.6425 - accuracy: 0.6662 - val_loss: 0.5846 - val_accuracy: 0.6292\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6877 - accuracy: 0.6425 - val_loss: 0.5457 - val_accuracy: 0.7416\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6484 - accuracy: 0.6875 - val_loss: 0.5382 - val_accuracy: 0.7191\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6328 - accuracy: 0.6625 - val_loss: 0.5422 - val_accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6343 - accuracy: 0.6800 - val_loss: 0.5377 - val_accuracy: 0.7416\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 114us/step - loss: 0.6428 - accuracy: 0.6762 - val_loss: 0.5436 - val_accuracy: 0.7191\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 86us/step - loss: 0.6416 - accuracy: 0.6825 - val_loss: 0.5625 - val_accuracy: 0.6292\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6417 - accuracy: 0.6650 - val_loss: 0.5472 - val_accuracy: 0.7416\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6269 - accuracy: 0.6762 - val_loss: 0.5368 - val_accuracy: 0.7640\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6231 - accuracy: 0.6762 - val_loss: 0.5387 - val_accuracy: 0.7640\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 76us/step - loss: 0.6107 - accuracy: 0.6850 - val_loss: 0.5519 - val_accuracy: 0.7416\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6452 - accuracy: 0.6562 - val_loss: 0.5340 - val_accuracy: 0.7753\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6385 - accuracy: 0.6850 - val_loss: 0.5376 - val_accuracy: 0.7528\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6175 - accuracy: 0.6800 - val_loss: 0.5375 - val_accuracy: 0.7079\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6252 - accuracy: 0.6787 - val_loss: 0.5312 - val_accuracy: 0.7079\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6188 - accuracy: 0.6938 - val_loss: 0.5312 - val_accuracy: 0.6966\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6283 - accuracy: 0.6800 - val_loss: 0.5352 - val_accuracy: 0.7303\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6201 - accuracy: 0.6787 - val_loss: 0.5415 - val_accuracy: 0.7191\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6254 - accuracy: 0.6712 - val_loss: 0.5330 - val_accuracy: 0.6966\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6300 - accuracy: 0.6888 - val_loss: 0.5524 - val_accuracy: 0.7079\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6232 - accuracy: 0.6575 - val_loss: 0.5353 - val_accuracy: 0.7416\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6265 - accuracy: 0.6950 - val_loss: 0.5354 - val_accuracy: 0.7079\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6186 - accuracy: 0.6812 - val_loss: 0.5486 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6253 - accuracy: 0.6775 - val_loss: 0.5482 - val_accuracy: 0.7079\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6184 - accuracy: 0.6812 - val_loss: 0.5316 - val_accuracy: 0.7191\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6169 - accuracy: 0.7000 - val_loss: 0.5483 - val_accuracy: 0.7303\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6039 - accuracy: 0.6862 - val_loss: 0.5456 - val_accuracy: 0.7303\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6120 - accuracy: 0.6925 - val_loss: 0.5413 - val_accuracy: 0.7416\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6205 - accuracy: 0.6800 - val_loss: 0.5384 - val_accuracy: 0.7416\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6186 - accuracy: 0.6800 - val_loss: 0.5346 - val_accuracy: 0.7416\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6186 - accuracy: 0.6762 - val_loss: 0.5330 - val_accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5972 - accuracy: 0.6775 - val_loss: 0.5360 - val_accuracy: 0.7528\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6191 - accuracy: 0.6825 - val_loss: 0.5487 - val_accuracy: 0.7191\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6069 - accuracy: 0.6800 - val_loss: 0.5322 - val_accuracy: 0.7416\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6257 - accuracy: 0.6875 - val_loss: 0.5300 - val_accuracy: 0.7191\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6120 - accuracy: 0.6825 - val_loss: 0.5391 - val_accuracy: 0.7303\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6132 - accuracy: 0.6950 - val_loss: 0.5283 - val_accuracy: 0.7416\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6064 - accuracy: 0.6900 - val_loss: 0.5307 - val_accuracy: 0.7640\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6199 - accuracy: 0.6925 - val_loss: 0.5425 - val_accuracy: 0.7640\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.6117 - accuracy: 0.6800 - val_loss: 0.5234 - val_accuracy: 0.7528\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 59us/step - loss: 0.6067 - accuracy: 0.6862 - val_loss: 0.5250 - val_accuracy: 0.7528\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6117 - accuracy: 0.6787 - val_loss: 0.5292 - val_accuracy: 0.7753\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.6098 - accuracy: 0.6950 - val_loss: 0.5251 - val_accuracy: 0.7416\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6228 - accuracy: 0.6750 - val_loss: 0.5218 - val_accuracy: 0.7640\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6178 - accuracy: 0.6862 - val_loss: 0.5341 - val_accuracy: 0.7640\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6030 - accuracy: 0.6913 - val_loss: 0.5273 - val_accuracy: 0.7303\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6019 - accuracy: 0.6787 - val_loss: 0.5263 - val_accuracy: 0.7528\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6053 - accuracy: 0.6875 - val_loss: 0.5218 - val_accuracy: 0.7191\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6096 - accuracy: 0.6938 - val_loss: 0.5340 - val_accuracy: 0.7416\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6182 - accuracy: 0.6850 - val_loss: 0.5366 - val_accuracy: 0.7416\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6030 - accuracy: 0.6850 - val_loss: 0.5239 - val_accuracy: 0.7079\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.6050 - accuracy: 0.7013 - val_loss: 0.5307 - val_accuracy: 0.7753\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.5918 - accuracy: 0.7075 - val_loss: 0.5197 - val_accuracy: 0.7303\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.5994 - accuracy: 0.6963 - val_loss: 0.5197 - val_accuracy: 0.7191\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6152 - accuracy: 0.6850 - val_loss: 0.5207 - val_accuracy: 0.7416\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6051 - accuracy: 0.6800 - val_loss: 0.5295 - val_accuracy: 0.7528\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.5890 - accuracy: 0.6925 - val_loss: 0.5280 - val_accuracy: 0.7303\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6086 - accuracy: 0.6800 - val_loss: 0.5314 - val_accuracy: 0.7640\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.5982 - accuracy: 0.6888 - val_loss: 0.5247 - val_accuracy: 0.7416\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.5878 - accuracy: 0.6975 - val_loss: 0.5305 - val_accuracy: 0.7640\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.5905 - accuracy: 0.6938 - val_loss: 0.5205 - val_accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6038 - accuracy: 0.6862 - val_loss: 0.5255 - val_accuracy: 0.7640\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.6104 - accuracy: 0.6700 - val_loss: 0.5309 - val_accuracy: 0.7753\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6012 - accuracy: 0.6925 - val_loss: 0.5250 - val_accuracy: 0.7416\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6190 - accuracy: 0.6837 - val_loss: 0.5272 - val_accuracy: 0.7416\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.5972 - accuracy: 0.6862 - val_loss: 0.5190 - val_accuracy: 0.7753\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6038 - accuracy: 0.6900 - val_loss: 0.5170 - val_accuracy: 0.7528\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6022 - accuracy: 0.6862 - val_loss: 0.5181 - val_accuracy: 0.7640\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.5993 - accuracy: 0.6850 - val_loss: 0.5194 - val_accuracy: 0.7528\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5920 - accuracy: 0.6938 - val_loss: 0.5198 - val_accuracy: 0.7640\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.6003 - accuracy: 0.6938 - val_loss: 0.5162 - val_accuracy: 0.7528\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6034 - accuracy: 0.6925 - val_loss: 0.5288 - val_accuracy: 0.7865\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5989 - accuracy: 0.6875 - val_loss: 0.5145 - val_accuracy: 0.7528\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5977 - accuracy: 0.6875 - val_loss: 0.5209 - val_accuracy: 0.7753\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.5965 - accuracy: 0.7000 - val_loss: 0.5182 - val_accuracy: 0.7640\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.5959 - accuracy: 0.7113 - val_loss: 0.5227 - val_accuracy: 0.7416\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6052 - accuracy: 0.6913 - val_loss: 0.5130 - val_accuracy: 0.7528\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6031 - accuracy: 0.6975 - val_loss: 0.5254 - val_accuracy: 0.7640\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 38us/step - loss: 0.5972 - accuracy: 0.6938 - val_loss: 0.5309 - val_accuracy: 0.7303\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.5922 - accuracy: 0.7038 - val_loss: 0.5213 - val_accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.5802 - accuracy: 0.6975 - val_loss: 0.5209 - val_accuracy: 0.7753\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5876 - accuracy: 0.6875 - val_loss: 0.5164 - val_accuracy: 0.7753\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6022 - accuracy: 0.6862 - val_loss: 0.5206 - val_accuracy: 0.7753\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.5996 - accuracy: 0.6888 - val_loss: 0.5113 - val_accuracy: 0.7528\n"
     ]
    }
   ],
   "source": [
    "relu_model_history = relu_model.fit(X, y, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model = Sequential()\n",
    "relu_adam_model.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model.add(Dropout(0.2))\n",
    "relu_adam_model.add(Dense(256,activation='relu'))\n",
    "relu_adam_model.add(Dropout(0.2))\n",
    "relu_adam_model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 572us/step - loss: 1.1692 - accuracy: 0.6087 - val_loss: 0.6660 - val_accuracy: 0.6854\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.9480 - accuracy: 0.5825 - val_loss: 0.5624 - val_accuracy: 0.6966\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.9190 - accuracy: 0.6275 - val_loss: 0.5723 - val_accuracy: 0.6966\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.8742 - accuracy: 0.6737 - val_loss: 0.6151 - val_accuracy: 0.6629\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.7791 - accuracy: 0.6450 - val_loss: 0.5293 - val_accuracy: 0.7191\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.8088 - accuracy: 0.6350 - val_loss: 0.5272 - val_accuracy: 0.7079\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6908 - accuracy: 0.6675 - val_loss: 0.4929 - val_accuracy: 0.7640\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.7430 - accuracy: 0.6662 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.7167 - accuracy: 0.6837 - val_loss: 0.4812 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.7034 - accuracy: 0.7088 - val_loss: 0.4846 - val_accuracy: 0.7753\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.7032 - accuracy: 0.6800 - val_loss: 0.4888 - val_accuracy: 0.7978\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6919 - accuracy: 0.6700 - val_loss: 0.4913 - val_accuracy: 0.7865\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6564 - accuracy: 0.6862 - val_loss: 0.4948 - val_accuracy: 0.7640\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 96us/step - loss: 0.6581 - accuracy: 0.6812 - val_loss: 0.4825 - val_accuracy: 0.7978\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6498 - accuracy: 0.6800 - val_loss: 0.5001 - val_accuracy: 0.7528\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6645 - accuracy: 0.6775 - val_loss: 0.4963 - val_accuracy: 0.7978\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6340 - accuracy: 0.6787 - val_loss: 0.4909 - val_accuracy: 0.7416\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6110 - accuracy: 0.7075 - val_loss: 0.4698 - val_accuracy: 0.8202\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6153 - accuracy: 0.7038 - val_loss: 0.4873 - val_accuracy: 0.7978\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6151 - accuracy: 0.6812 - val_loss: 0.4728 - val_accuracy: 0.7865\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6177 - accuracy: 0.6988 - val_loss: 0.4678 - val_accuracy: 0.7640\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5894 - accuracy: 0.7150 - val_loss: 0.4850 - val_accuracy: 0.7753\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5822 - accuracy: 0.6900 - val_loss: 0.4855 - val_accuracy: 0.7865\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.5748 - accuracy: 0.7275 - val_loss: 0.4695 - val_accuracy: 0.8090\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.5631 - accuracy: 0.7237 - val_loss: 0.4727 - val_accuracy: 0.7753\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5860 - accuracy: 0.7150 - val_loss: 0.4560 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6154 - accuracy: 0.7175 - val_loss: 0.4603 - val_accuracy: 0.7753\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5691 - accuracy: 0.7013 - val_loss: 0.4783 - val_accuracy: 0.7865\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5836 - accuracy: 0.7262 - val_loss: 0.4697 - val_accuracy: 0.7865\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5584 - accuracy: 0.7275 - val_loss: 0.4597 - val_accuracy: 0.7865\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5680 - accuracy: 0.6975 - val_loss: 0.4623 - val_accuracy: 0.8202\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5470 - accuracy: 0.7375 - val_loss: 0.4448 - val_accuracy: 0.7753\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5555 - accuracy: 0.7325 - val_loss: 0.4342 - val_accuracy: 0.7753\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5529 - accuracy: 0.7337 - val_loss: 0.4309 - val_accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5440 - accuracy: 0.7287 - val_loss: 0.4379 - val_accuracy: 0.8202\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5384 - accuracy: 0.7538 - val_loss: 0.4361 - val_accuracy: 0.8090\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5415 - accuracy: 0.7563 - val_loss: 0.4271 - val_accuracy: 0.8090\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5212 - accuracy: 0.7500 - val_loss: 0.4214 - val_accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5331 - accuracy: 0.7563 - val_loss: 0.4102 - val_accuracy: 0.8090\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5210 - accuracy: 0.7550 - val_loss: 0.4147 - val_accuracy: 0.8202\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5153 - accuracy: 0.7675 - val_loss: 0.4112 - val_accuracy: 0.8427\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5119 - accuracy: 0.7538 - val_loss: 0.4147 - val_accuracy: 0.8202\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5188 - accuracy: 0.7825 - val_loss: 0.4123 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5366 - accuracy: 0.7525 - val_loss: 0.4086 - val_accuracy: 0.8202\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5253 - accuracy: 0.7700 - val_loss: 0.4185 - val_accuracy: 0.7978\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5299 - accuracy: 0.7725 - val_loss: 0.4278 - val_accuracy: 0.8315\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 103us/step - loss: 0.5348 - accuracy: 0.7600 - val_loss: 0.4223 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.5110 - accuracy: 0.7688 - val_loss: 0.4103 - val_accuracy: 0.8202\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.5058 - accuracy: 0.7750 - val_loss: 0.4042 - val_accuracy: 0.8090\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.5056 - accuracy: 0.7800 - val_loss: 0.4323 - val_accuracy: 0.8315\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5082 - accuracy: 0.7675 - val_loss: 0.4063 - val_accuracy: 0.8202\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4930 - accuracy: 0.7937 - val_loss: 0.4188 - val_accuracy: 0.8427\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5044 - accuracy: 0.7875 - val_loss: 0.4046 - val_accuracy: 0.8090\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5225 - accuracy: 0.7613 - val_loss: 0.4050 - val_accuracy: 0.8090\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5187 - accuracy: 0.7663 - val_loss: 0.4039 - val_accuracy: 0.8202\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5172 - accuracy: 0.7812 - val_loss: 0.4146 - val_accuracy: 0.8315\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 44us/step - loss: 0.5057 - accuracy: 0.7700 - val_loss: 0.4174 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5098 - accuracy: 0.7812 - val_loss: 0.4062 - val_accuracy: 0.8315\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4953 - accuracy: 0.7900 - val_loss: 0.4033 - val_accuracy: 0.8315\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5071 - accuracy: 0.7663 - val_loss: 0.3992 - val_accuracy: 0.8315\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5066 - accuracy: 0.7688 - val_loss: 0.4020 - val_accuracy: 0.8202\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5164 - accuracy: 0.7675 - val_loss: 0.4026 - val_accuracy: 0.8202\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4761 - accuracy: 0.7812 - val_loss: 0.4082 - val_accuracy: 0.8315\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4857 - accuracy: 0.7825 - val_loss: 0.3871 - val_accuracy: 0.8202\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4956 - accuracy: 0.7812 - val_loss: 0.3890 - val_accuracy: 0.8315\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4924 - accuracy: 0.7925 - val_loss: 0.3896 - val_accuracy: 0.8315\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4882 - accuracy: 0.7887 - val_loss: 0.3829 - val_accuracy: 0.8315\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4946 - accuracy: 0.7937 - val_loss: 0.3881 - val_accuracy: 0.8315\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5049 - accuracy: 0.7788 - val_loss: 0.3843 - val_accuracy: 0.8202\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4774 - accuracy: 0.7900 - val_loss: 0.3966 - val_accuracy: 0.8427\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4781 - accuracy: 0.7788 - val_loss: 0.4001 - val_accuracy: 0.8539\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 85us/step - loss: 0.4953 - accuracy: 0.7763 - val_loss: 0.3852 - val_accuracy: 0.8427\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4977 - accuracy: 0.7812 - val_loss: 0.3844 - val_accuracy: 0.8315\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.4726 - accuracy: 0.7900 - val_loss: 0.3893 - val_accuracy: 0.8315\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4777 - accuracy: 0.7937 - val_loss: 0.3893 - val_accuracy: 0.8315\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4756 - accuracy: 0.7937 - val_loss: 0.3714 - val_accuracy: 0.8427\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4941 - accuracy: 0.7738 - val_loss: 0.3724 - val_accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4907 - accuracy: 0.7887 - val_loss: 0.4122 - val_accuracy: 0.8539\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4777 - accuracy: 0.7900 - val_loss: 0.4052 - val_accuracy: 0.8315\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4963 - accuracy: 0.7837 - val_loss: 0.3835 - val_accuracy: 0.8315\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4624 - accuracy: 0.7962 - val_loss: 0.3772 - val_accuracy: 0.8315\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4732 - accuracy: 0.7862 - val_loss: 0.3801 - val_accuracy: 0.8315\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.4639 - accuracy: 0.8012 - val_loss: 0.3816 - val_accuracy: 0.8315\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4707 - accuracy: 0.7900 - val_loss: 0.3841 - val_accuracy: 0.8427\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4655 - accuracy: 0.7962 - val_loss: 0.3728 - val_accuracy: 0.8427\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4611 - accuracy: 0.8025 - val_loss: 0.3891 - val_accuracy: 0.8427\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4602 - accuracy: 0.7962 - val_loss: 0.3755 - val_accuracy: 0.8315\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4560 - accuracy: 0.8100 - val_loss: 0.3837 - val_accuracy: 0.8427\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4867 - accuracy: 0.7937 - val_loss: 0.3721 - val_accuracy: 0.8427\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.4768 - accuracy: 0.7925 - val_loss: 0.3749 - val_accuracy: 0.8539\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4668 - accuracy: 0.7912 - val_loss: 0.3796 - val_accuracy: 0.8427\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4491 - accuracy: 0.8075 - val_loss: 0.3660 - val_accuracy: 0.8427\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4831 - accuracy: 0.7725 - val_loss: 0.3779 - val_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.4667 - accuracy: 0.8087 - val_loss: 0.3766 - val_accuracy: 0.8315\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 82us/step - loss: 0.4617 - accuracy: 0.7912 - val_loss: 0.3819 - val_accuracy: 0.8315\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.4562 - accuracy: 0.8012 - val_loss: 0.3720 - val_accuracy: 0.8427\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.4550 - accuracy: 0.8075 - val_loss: 0.3752 - val_accuracy: 0.8315\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.4651 - accuracy: 0.8000 - val_loss: 0.3808 - val_accuracy: 0.8315\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4587 - accuracy: 0.7975 - val_loss: 0.3712 - val_accuracy: 0.8427\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.4491 - accuracy: 0.7937 - val_loss: 0.3690 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "relu_adam_model_history = relu_adam_model.fit(X, y, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Accuracy so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_01 = Sequential()\n",
    "relu_adam_model_01.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model_01.add(Dropout(0.2))\n",
    "relu_adam_model_01.add(Dense(256,activation='relu'))\n",
    "relu_adam_model_01.add(Dropout(0.2))\n",
    "relu_adam_model_01.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_01.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 1s 959us/step - loss: 3.5405 - accuracy: 0.5612 - val_loss: 1.4692 - val_accuracy: 0.7191\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 81us/step - loss: 1.7610 - accuracy: 0.6200 - val_loss: 0.7863 - val_accuracy: 0.6629\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 136us/step - loss: 0.8551 - accuracy: 0.6612 - val_loss: 0.5968 - val_accuracy: 0.7416\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 119us/step - loss: 0.6662 - accuracy: 0.6562 - val_loss: 0.5376 - val_accuracy: 0.6854\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.6484 - accuracy: 0.6800 - val_loss: 0.5435 - val_accuracy: 0.7303\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6150 - accuracy: 0.6687 - val_loss: 0.5302 - val_accuracy: 0.7528\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.6011 - accuracy: 0.6975 - val_loss: 0.5111 - val_accuracy: 0.7640\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 105us/step - loss: 0.5870 - accuracy: 0.6988 - val_loss: 0.5240 - val_accuracy: 0.7528\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 296us/step - loss: 0.6059 - accuracy: 0.6812 - val_loss: 0.5145 - val_accuracy: 0.7416\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5850 - accuracy: 0.6925 - val_loss: 0.4954 - val_accuracy: 0.7528\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5782 - accuracy: 0.6938 - val_loss: 0.4871 - val_accuracy: 0.7753\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5912 - accuracy: 0.6888 - val_loss: 0.5086 - val_accuracy: 0.7753\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5746 - accuracy: 0.7237 - val_loss: 0.4796 - val_accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.166384). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5756 - accuracy: 0.7100 - val_loss: 0.4580 - val_accuracy: 0.7753\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5753 - accuracy: 0.7125 - val_loss: 0.4786 - val_accuracy: 0.7865\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.5474 - accuracy: 0.7250 - val_loss: 0.4326 - val_accuracy: 0.7753\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5304 - accuracy: 0.7425 - val_loss: 0.4404 - val_accuracy: 0.7865\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5213 - accuracy: 0.7450 - val_loss: 0.4223 - val_accuracy: 0.8202\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5206 - accuracy: 0.7600 - val_loss: 0.4318 - val_accuracy: 0.7865\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.5154 - accuracy: 0.7650 - val_loss: 0.4352 - val_accuracy: 0.7978\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5094 - accuracy: 0.7663 - val_loss: 0.4170 - val_accuracy: 0.8202\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.5059 - accuracy: 0.7875 - val_loss: 0.4163 - val_accuracy: 0.8202\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.5002 - accuracy: 0.7663 - val_loss: 0.4052 - val_accuracy: 0.8427\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 127us/step - loss: 0.5218 - accuracy: 0.7625 - val_loss: 0.4102 - val_accuracy: 0.8427\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 78us/step - loss: 0.5134 - accuracy: 0.7738 - val_loss: 0.4128 - val_accuracy: 0.7978\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4938 - accuracy: 0.7738 - val_loss: 0.3987 - val_accuracy: 0.8315\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.4972 - accuracy: 0.7800 - val_loss: 0.3971 - val_accuracy: 0.8539\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4752 - accuracy: 0.7975 - val_loss: 0.3822 - val_accuracy: 0.8427\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4875 - accuracy: 0.7912 - val_loss: 0.3824 - val_accuracy: 0.8539\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4784 - accuracy: 0.7962 - val_loss: 0.3710 - val_accuracy: 0.8315\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4561 - accuracy: 0.8012 - val_loss: 0.3846 - val_accuracy: 0.8539\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4678 - accuracy: 0.7975 - val_loss: 0.3840 - val_accuracy: 0.8427\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5040 - accuracy: 0.7675 - val_loss: 0.4091 - val_accuracy: 0.8427\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4981 - accuracy: 0.7775 - val_loss: 0.4143 - val_accuracy: 0.8315\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4832 - accuracy: 0.7750 - val_loss: 0.3892 - val_accuracy: 0.8315\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4732 - accuracy: 0.7937 - val_loss: 0.3613 - val_accuracy: 0.8539\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4877 - accuracy: 0.7750 - val_loss: 0.4201 - val_accuracy: 0.8202\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4909 - accuracy: 0.7850 - val_loss: 0.3766 - val_accuracy: 0.8315\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4635 - accuracy: 0.7800 - val_loss: 0.3517 - val_accuracy: 0.8427\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4603 - accuracy: 0.8037 - val_loss: 0.3614 - val_accuracy: 0.8315\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4645 - accuracy: 0.8012 - val_loss: 0.3564 - val_accuracy: 0.8539\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.4626 - accuracy: 0.8087 - val_loss: 0.3668 - val_accuracy: 0.8539\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4588 - accuracy: 0.7862 - val_loss: 0.3873 - val_accuracy: 0.8315\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.4900 - accuracy: 0.7900 - val_loss: 0.3744 - val_accuracy: 0.8539\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4689 - accuracy: 0.7900 - val_loss: 0.3646 - val_accuracy: 0.8427\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4490 - accuracy: 0.8037 - val_loss: 0.3571 - val_accuracy: 0.8315\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.4689 - accuracy: 0.7887 - val_loss: 0.3508 - val_accuracy: 0.8315\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4481 - accuracy: 0.8050 - val_loss: 0.4201 - val_accuracy: 0.7978\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4574 - accuracy: 0.8025 - val_loss: 0.3716 - val_accuracy: 0.8427\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.4746 - accuracy: 0.7937 - val_loss: 0.3904 - val_accuracy: 0.8652\n"
     ]
    }
   ],
   "source": [
    "relu_adam_model_01_history = relu_adam_model_01.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../titanic/cleaned_test.csv')\n",
    "passengerID = test_data['PassengerId']\n",
    "test_data.drop('PassengerId',axis = 1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01227462e-01],\n",
       "       [2.68520713e-01],\n",
       "       [6.74698055e-02],\n",
       "       [9.37634408e-02],\n",
       "       [4.10224140e-01],\n",
       "       [1.18794948e-01],\n",
       "       [4.70117658e-01],\n",
       "       [1.78667933e-01],\n",
       "       [4.92077380e-01],\n",
       "       [1.35193467e-01],\n",
       "       [9.32487547e-02],\n",
       "       [2.23482609e-01],\n",
       "       [7.13174522e-01],\n",
       "       [1.12855762e-01],\n",
       "       [6.52873755e-01],\n",
       "       [6.09354317e-01],\n",
       "       [1.36621743e-01],\n",
       "       [1.12316132e-01],\n",
       "       [3.75655442e-01],\n",
       "       [3.10107172e-01],\n",
       "       [3.33341360e-01],\n",
       "       [3.90746236e-01],\n",
       "       [6.64274573e-01],\n",
       "       [4.25233066e-01],\n",
       "       [6.99481964e-01],\n",
       "       [7.70401657e-02],\n",
       "       [6.62936091e-01],\n",
       "       [1.11804247e-01],\n",
       "       [2.99082220e-01],\n",
       "       [1.41856700e-01],\n",
       "       [1.53250217e-01],\n",
       "       [1.41828984e-01],\n",
       "       [3.73282909e-01],\n",
       "       [4.09196556e-01],\n",
       "       [3.54320168e-01],\n",
       "       [1.14680141e-01],\n",
       "       [4.39401269e-01],\n",
       "       [4.68316168e-01],\n",
       "       [9.46387649e-02],\n",
       "       [4.11799610e-01],\n",
       "       [1.18159980e-01],\n",
       "       [2.77783275e-01],\n",
       "       [7.73579478e-02],\n",
       "       [5.17499983e-01],\n",
       "       [6.44982338e-01],\n",
       "       [9.32112336e-02],\n",
       "       [2.60708034e-01],\n",
       "       [9.95407701e-02],\n",
       "       [6.45372391e-01],\n",
       "       [3.69764566e-01],\n",
       "       [3.39085162e-01],\n",
       "       [1.74595565e-01],\n",
       "       [3.55213940e-01],\n",
       "       [7.00559676e-01],\n",
       "       [1.74122185e-01],\n",
       "       [1.47203207e-02],\n",
       "       [9.09632742e-02],\n",
       "       [9.29049551e-02],\n",
       "       [1.21346176e-01],\n",
       "       [7.54848838e-01],\n",
       "       [1.03252530e-01],\n",
       "       [1.23428255e-01],\n",
       "       [1.00064844e-01],\n",
       "       [5.59228420e-01],\n",
       "       [7.68515706e-01],\n",
       "       [6.31964207e-01],\n",
       "       [6.07028604e-01],\n",
       "       [3.46348107e-01],\n",
       "       [3.11553419e-01],\n",
       "       [6.94915831e-01],\n",
       "       [5.38975120e-01],\n",
       "       [9.39033031e-02],\n",
       "       [4.07814652e-01],\n",
       "       [3.08992445e-01],\n",
       "       [7.66153991e-01],\n",
       "       [6.49442434e-01],\n",
       "       [9.33910012e-02],\n",
       "       [3.84657741e-01],\n",
       "       [1.21353775e-01],\n",
       "       [5.38975120e-01],\n",
       "       [6.33716345e-01],\n",
       "       [5.94157279e-01],\n",
       "       [2.05560207e-01],\n",
       "       [9.32487547e-02],\n",
       "       [1.28875583e-01],\n",
       "       [1.34404778e-01],\n",
       "       [5.09631336e-01],\n",
       "       [4.73804951e-01],\n",
       "       [5.38975120e-01],\n",
       "       [9.12828326e-01],\n",
       "       [4.64426756e-01],\n",
       "       [9.31375027e-02],\n",
       "       [5.53014159e-01],\n",
       "       [9.33910012e-02],\n",
       "       [2.99188197e-01],\n",
       "       [9.30922329e-02],\n",
       "       [5.69150209e-01],\n",
       "       [9.43706036e-02],\n",
       "       [4.60175008e-01],\n",
       "       [9.66667235e-02],\n",
       "       [6.04831457e-01],\n",
       "       [1.92966968e-01],\n",
       "       [9.95407701e-02],\n",
       "       [9.29969847e-02],\n",
       "       [4.28694129e-01],\n",
       "       [1.81865782e-01],\n",
       "       [1.06074780e-01],\n",
       "       [9.95407701e-02],\n",
       "       [9.39990282e-02],\n",
       "       [1.55218631e-01],\n",
       "       [1.45968497e-01],\n",
       "       [5.39659739e-01],\n",
       "       [6.19655132e-01],\n",
       "       [5.87295830e-01],\n",
       "       [7.62956619e-01],\n",
       "       [1.52872473e-01],\n",
       "       [1.10244155e-01],\n",
       "       [9.43737447e-01],\n",
       "       [4.60564464e-01],\n",
       "       [5.91458499e-01],\n",
       "       [7.36860275e-01],\n",
       "       [8.81893635e-02],\n",
       "       [6.31146610e-01],\n",
       "       [9.34247673e-02],\n",
       "       [9.95407701e-02],\n",
       "       [5.45412838e-01],\n",
       "       [9.30924416e-02],\n",
       "       [5.04360378e-01],\n",
       "       [1.12513989e-01],\n",
       "       [9.33910012e-02],\n",
       "       [9.67975259e-02],\n",
       "       [2.00647086e-01],\n",
       "       [4.23575759e-01],\n",
       "       [9.86772776e-02],\n",
       "       [7.34922886e-02],\n",
       "       [9.32103693e-02],\n",
       "       [1.12749308e-01],\n",
       "       [1.30525947e-01],\n",
       "       [4.45062965e-01],\n",
       "       [1.07068121e-01],\n",
       "       [2.40254104e-02],\n",
       "       [7.85993099e-01],\n",
       "       [5.59810698e-01],\n",
       "       [2.51523197e-01],\n",
       "       [2.54609942e-01],\n",
       "       [8.90013576e-02],\n",
       "       [4.26381528e-01],\n",
       "       [9.33146477e-02],\n",
       "       [2.77783275e-01],\n",
       "       [1.67068690e-01],\n",
       "       [6.68942630e-01],\n",
       "       [1.13063186e-01],\n",
       "       [3.46622199e-01],\n",
       "       [2.22212970e-02],\n",
       "       [9.28475559e-02],\n",
       "       [7.46109903e-01],\n",
       "       [4.41685081e-01],\n",
       "       [2.54609942e-01],\n",
       "       [4.25066501e-01],\n",
       "       [5.38583457e-01],\n",
       "       [5.16037285e-01],\n",
       "       [5.58767021e-01],\n",
       "       [9.20892656e-02],\n",
       "       [1.15103751e-01],\n",
       "       [4.55645829e-01],\n",
       "       [3.63260061e-01],\n",
       "       [1.06210858e-01],\n",
       "       [5.79723299e-01],\n",
       "       [4.67743248e-01],\n",
       "       [9.28475559e-02],\n",
       "       [1.13210052e-01],\n",
       "       [1.10133886e-01],\n",
       "       [1.11730486e-01],\n",
       "       [9.44592655e-02],\n",
       "       [6.20686054e-01],\n",
       "       [7.73148179e-01],\n",
       "       [3.22924078e-01],\n",
       "       [4.94414210e-01],\n",
       "       [5.30766308e-01],\n",
       "       [1.21353775e-01],\n",
       "       [3.83365273e-01],\n",
       "       [7.12123513e-01],\n",
       "       [9.95407701e-02],\n",
       "       [7.17127085e-01],\n",
       "       [1.36849076e-01],\n",
       "       [6.16426289e-01],\n",
       "       [8.17259848e-02],\n",
       "       [2.77721882e-03],\n",
       "       [1.17745280e-01],\n",
       "       [1.82308286e-01],\n",
       "       [2.72394121e-01],\n",
       "       [1.91909879e-01],\n",
       "       [8.06543827e-02],\n",
       "       [8.33891988e-01],\n",
       "       [9.56954658e-02],\n",
       "       [7.27107823e-01],\n",
       "       [4.69872057e-01],\n",
       "       [1.21995747e-01],\n",
       "       [4.40443724e-01],\n",
       "       [7.05283940e-01],\n",
       "       [9.93132591e-01],\n",
       "       [6.24588847e-01],\n",
       "       [4.98289555e-01],\n",
       "       [1.17008418e-01],\n",
       "       [2.77533442e-01],\n",
       "       [4.38320160e-01],\n",
       "       [1.19114041e-01],\n",
       "       [6.21170998e-01],\n",
       "       [9.31843519e-02],\n",
       "       [1.70567811e-01],\n",
       "       [9.21580195e-02],\n",
       "       [5.26879728e-01],\n",
       "       [3.78105462e-01],\n",
       "       [2.93777585e-01],\n",
       "       [3.71081054e-01],\n",
       "       [5.42003214e-01],\n",
       "       [4.92388546e-01],\n",
       "       [7.26674438e-01],\n",
       "       [9.33910012e-02],\n",
       "       [4.61071849e-01],\n",
       "       [9.46829915e-02],\n",
       "       [5.52128136e-01],\n",
       "       [9.34394598e-02],\n",
       "       [4.82525527e-01],\n",
       "       [4.47811633e-01],\n",
       "       [9.31539237e-02],\n",
       "       [5.38975120e-01],\n",
       "       [1.07394367e-01],\n",
       "       [1.25717968e-01],\n",
       "       [5.04400849e-01],\n",
       "       [7.73238838e-01],\n",
       "       [8.12796056e-02],\n",
       "       [1.00102067e-01],\n",
       "       [4.04895008e-01],\n",
       "       [9.59549546e-02],\n",
       "       [3.42160463e-01],\n",
       "       [1.13295346e-01],\n",
       "       [4.61705625e-01],\n",
       "       [6.60819590e-01],\n",
       "       [4.71028894e-01],\n",
       "       [4.35026109e-01],\n",
       "       [4.71994936e-01],\n",
       "       [9.32411253e-02],\n",
       "       [1.41351700e-01],\n",
       "       [3.27979803e-01],\n",
       "       [7.17157543e-01],\n",
       "       [1.71225756e-01],\n",
       "       [5.91458499e-01],\n",
       "       [4.80569899e-01],\n",
       "       [9.35666919e-01],\n",
       "       [9.63209271e-02],\n",
       "       [5.58777630e-01],\n",
       "       [9.49069560e-02],\n",
       "       [9.68233049e-02],\n",
       "       [9.28475559e-02],\n",
       "       [9.95407701e-02],\n",
       "       [9.35798883e-02],\n",
       "       [6.35279536e-01],\n",
       "       [9.33431983e-02],\n",
       "       [9.79204476e-02],\n",
       "       [9.37100351e-02],\n",
       "       [5.03516734e-01],\n",
       "       [9.43473697e-01],\n",
       "       [1.50427818e-01],\n",
       "       [9.32487547e-02],\n",
       "       [6.23255372e-02],\n",
       "       [9.28475559e-02],\n",
       "       [4.39401269e-01],\n",
       "       [1.07517689e-01],\n",
       "       [4.30176377e-01],\n",
       "       [9.95407701e-02],\n",
       "       [7.06166863e-01],\n",
       "       [5.89423954e-01],\n",
       "       [1.11722082e-01],\n",
       "       [6.33484304e-01],\n",
       "       [1.16712719e-01],\n",
       "       [1.67281210e-01],\n",
       "       [1.55306220e-01],\n",
       "       [1.25007719e-01],\n",
       "       [4.56173420e-01],\n",
       "       [9.71434355e-01],\n",
       "       [5.38975120e-01],\n",
       "       [4.70260680e-01],\n",
       "       [9.25361514e-01],\n",
       "       [8.56703818e-02],\n",
       "       [9.24332738e-02],\n",
       "       [4.24878687e-01],\n",
       "       [1.11730486e-01],\n",
       "       [9.33910012e-02],\n",
       "       [3.63859773e-01],\n",
       "       [4.60363448e-01],\n",
       "       [1.11730486e-01],\n",
       "       [3.74721646e-01],\n",
       "       [9.54008996e-02],\n",
       "       [9.31199491e-02],\n",
       "       [8.72537971e-01],\n",
       "       [1.41856700e-01],\n",
       "       [4.11350191e-01],\n",
       "       [9.43636596e-02],\n",
       "       [9.67160463e-02],\n",
       "       [1.69127643e-01],\n",
       "       [1.44199044e-01],\n",
       "       [9.39547420e-02],\n",
       "       [5.38975120e-01],\n",
       "       [3.16537112e-01],\n",
       "       [5.22552013e-01],\n",
       "       [9.86569166e-01],\n",
       "       [3.88128251e-01],\n",
       "       [3.51444691e-01],\n",
       "       [1.05019659e-01],\n",
       "       [1.11831605e-01],\n",
       "       [9.28821862e-02],\n",
       "       [4.24932897e-01],\n",
       "       [7.36818075e-01],\n",
       "       [6.12900615e-01],\n",
       "       [4.74587828e-01],\n",
       "       [1.33938700e-01],\n",
       "       [9.31526423e-02],\n",
       "       [1.38508618e-01],\n",
       "       [9.29969847e-02],\n",
       "       [1.11761779e-01],\n",
       "       [1.30525947e-01],\n",
       "       [2.90255427e-01],\n",
       "       [8.00613344e-01],\n",
       "       [9.22067165e-02],\n",
       "       [3.39980900e-01],\n",
       "       [4.37605768e-01],\n",
       "       [1.90964937e-01],\n",
       "       [1.46403223e-01],\n",
       "       [4.60930169e-01],\n",
       "       [2.98530996e-01],\n",
       "       [1.11722082e-01],\n",
       "       [4.42868799e-01],\n",
       "       [9.31793153e-02],\n",
       "       [2.87723303e-01],\n",
       "       [1.22158080e-01],\n",
       "       [8.31546485e-02],\n",
       "       [2.98051000e-01],\n",
       "       [1.11730486e-01],\n",
       "       [1.37013972e-01],\n",
       "       [9.66467857e-02],\n",
       "       [1.35980487e-01],\n",
       "       [8.30309033e-01],\n",
       "       [1.13744795e-01],\n",
       "       [4.71723944e-01],\n",
       "       [1.30525947e-01],\n",
       "       [3.52931380e-01],\n",
       "       [1.41197652e-01],\n",
       "       [6.09902143e-01],\n",
       "       [6.00279927e-01],\n",
       "       [1.17008418e-01],\n",
       "       [5.19929230e-01],\n",
       "       [2.25668103e-01],\n",
       "       [9.70942855e-01],\n",
       "       [1.99853480e-01],\n",
       "       [5.02813399e-01],\n",
       "       [9.32334363e-02],\n",
       "       [9.95407701e-02],\n",
       "       [4.52721298e-01],\n",
       "       [3.18259001e-04],\n",
       "       [5.39320946e-01],\n",
       "       [6.09902143e-01],\n",
       "       [9.37634408e-02],\n",
       "       [6.63708508e-01],\n",
       "       [3.10526013e-01],\n",
       "       [1.34430289e-01],\n",
       "       [7.54599750e-01],\n",
       "       [5.91373682e-01],\n",
       "       [1.58741683e-01],\n",
       "       [1.20651543e-01],\n",
       "       [7.52383351e-01],\n",
       "       [4.28690910e-02],\n",
       "       [1.07483596e-01],\n",
       "       [5.87765753e-01],\n",
       "       [7.98081040e-01],\n",
       "       [4.11612123e-01],\n",
       "       [1.34931177e-01],\n",
       "       [3.36484671e-01],\n",
       "       [4.10430133e-02],\n",
       "       [9.95407701e-02],\n",
       "       [9.81256962e-02],\n",
       "       [5.47183514e-01],\n",
       "       [4.92359161e-01],\n",
       "       [1.22097194e-01],\n",
       "       [5.77167094e-01],\n",
       "       [9.31375027e-02],\n",
       "       [8.05381536e-02],\n",
       "       [1.05614871e-01],\n",
       "       [7.49689043e-02],\n",
       "       [5.48568606e-01],\n",
       "       [5.24152815e-01],\n",
       "       [4.09682155e-01],\n",
       "       [8.80481601e-02],\n",
       "       [9.37862396e-02],\n",
       "       [7.11146295e-01],\n",
       "       [9.73946154e-02],\n",
       "       [5.70506692e-01],\n",
       "       [9.30742919e-02],\n",
       "       [1.00190163e-01],\n",
       "       [7.73179829e-01],\n",
       "       [1.34799927e-01],\n",
       "       [6.60144329e-01],\n",
       "       [4.39189762e-01],\n",
       "       [2.13101834e-01],\n",
       "       [1.86742038e-01],\n",
       "       [1.09183043e-01],\n",
       "       [5.72249055e-01],\n",
       "       [5.38290322e-01],\n",
       "       [9.01491165e-01],\n",
       "       [5.38975120e-01],\n",
       "       [7.56217122e-01],\n",
       "       [4.11111653e-01],\n",
       "       [9.33910012e-02],\n",
       "       [7.49750257e-01],\n",
       "       [8.01558793e-02],\n",
       "       [9.33910012e-02],\n",
       "       [1.59550965e-01]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = relu_adam_model_01.predict(test_data) \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.101227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.268521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.067470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.410224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.118795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.470118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.178668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.492077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.135193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surv\n",
       "0  0.101227\n",
       "1  0.268521\n",
       "2  0.067470\n",
       "3  0.093763\n",
       "4  0.410224\n",
       "5  0.118795\n",
       "6  0.470118\n",
       "7  0.178668\n",
       "8  0.492077\n",
       "9  0.135193"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = pd.DataFrame(data=predictions,columns=['Surv'])\n",
    "predict_df.head(10)\n",
    "# submission = pd.concat([passenferID,predict_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.loc[(predict_df['Surv']>0.6),'Survived'] = 1\n",
    "predict_df.loc[(predict_df['Surv']<=0.6),'Survived'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     0.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    1.0\n",
       "13    0.0\n",
       "14    1.0\n",
       "15    1.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    1.0\n",
       "23    0.0\n",
       "24    1.0\n",
       "25    0.0\n",
       "26    1.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "36    0.0\n",
       "37    0.0\n",
       "38    0.0\n",
       "39    0.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived = predict_df['Survived']\n",
    "survived.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([passengerID,survived],axis=1)\n",
    "submission.astype('int32')\n",
    "submission.to_csv(\"../submissions/NN_submission2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_0001 = Sequential()\n",
    "relu_adam_model_0001.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model_0001.add(Dropout(0.2))\n",
    "relu_adam_model_0001.add(Dense(256,activation='relu'))\n",
    "relu_adam_model_0001.add(Dropout(0.2))\n",
    "relu_adam_model_0001.add(Dense(2,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_0001 = optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_0001.compile(optimizer=adam_0001,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_21 to have shape (2,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e3d8baa3f237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrelu_adam_model_0001_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu_adam_model_0001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_21 to have shape (2,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "relu_adam_model_0001_history = relu_adam_model_0001.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
